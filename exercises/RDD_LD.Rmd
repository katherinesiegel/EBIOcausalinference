---
title: "Regression Discontinuinty Designs"
author: "Laura Dee & Katherine Siegel"
date: "3/20/2023"
output: html_document
---

<!-- https://rpubs.com/phle/r_tutorial_regression_discontinuity_design -->

## Set up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### Install packages
install.packages("rdrobust",
                 repos = "http://cran.us.r-project.org")
install.packages("rddensity",
                 repos = "http://cran.us.r-project.org")

### Load all packages needed
library(tidyverse)  # ggplot(), %>%, mutate(), and friends
# library(broom)  # Convert models to data frames
library(rdrobust)  # For robust nonparametric regression discontinuity
library(rddensity)  # For nonparametric regression discontinuity density tests
# library(modelsummary)  # Create side-by-side regression tables
```

## The key concept

A threshold in a continuous variable determines treatment assignment 

Running variable (or “score”), X: a continuously distributed variable with a clearly defined cutoff (c) that determines which units are assigned to treatment and which ones are assigned to control.

Prior to the treatment, the outcome should not differ between the treatment and control group (*continuity assumption*). The distribution of the variable which indicates the threshold should have no jumps around this cutoff value.

```{r echo=FALSE, out.width="75%",fig.cap="Example using an arbitrary test score cut-off for being enrolled in tutoring programs on learning outcomes, from Andrew Heiss", out.width='70%', echo=F } 
knitr::include_graphics("rdd_demo/testscore_example.png", error = FALSE)
```


## There are two different variants of the RDD:

> * sharp RDD: the threshold separates the treatment and control group exactly
>
> * fuzzy RDD: the threshold influences the probability of being treated.  this is in fact an instrumental variable approach (estimating a Local Average Treatment Effect [LATE])

The value of the outcome (Y) for individuals just below the threshold is the missing counterfactual outcome. It increases continuously with the cutoff variable, as opposed to the treatment.

Here are some nice elaborations and figures on these two variants of RDD from the [World Bank](https://dimewiki.worldbank.org/Regression_Discontinuity)

```{r echo=FALSE, out.width="75%",fig.cap="Sharp vs Fuzzy RDD illustration from the World Bank", out.width='70%', echo=F } 
knitr::include_graphics("rdd_demo/worldbankRDD.png", error = FALSE)
```

### Sharp RDD
In sharp designs, the probability of treatment changes from 0 to 1 at the cutoff. There are no cross-overs and no non-complance. For example, if a scholarship award is given to all students above a threshold test score of 80%, then the assignment rule defines treatment status deterministically with probabilities of 0 or 1. Thus, the design is sharp.

### Fuzzy RDD
In fuzzy designs, the probability of treatment is discontinuous at the cutoff, but not to the degree of a definitive 0 to 1 jump. For example, if food stamp eligibility is given to all households below a certain income, but not all households receive the food stamps, then the assignment rule defines treatment status probabilistically but not perfectly. Thus, the design is fuzzy. The fuzziness may result from imperfect compliance with the law/rule/program; imperfect implementation that treated some non-eligible units or neglected to treat some eligible units; spillover effects; or manipulation of the eligibility index.

A fuzzy design assumes that, in the absence of the assignment rule, some of those who take up the treatment would not have participated in the program. The eligibility index acts as a nudge. The subgroup that participates in a program due to the selection rule is called compliers (see e.g. [Angrist and Imbens (1994)](https://pdfs.semanticscholar.org/8714/260129e51abb09fd89d6ff79065af17bb106.pdf), and [Imbens, Angrist, and Rubin (1996))](http://www.math.mcgill.ca/dstephens/AngristIV1996-JASA-Combined.pdf); under the RDD, the treatment effects are estimated only for the group of compliers."

### Advantages of RDD
With an RDD approach some assumptions can be tested. Individuals or units close to the threshold are nearly identical, except for characteristics which are affected by the treatment.

RDD's strengths include that we can:

* illustrate the design graphically
* test some of the underlying assumptions and support arguments through data visualization
* reliably (unbiased) estimates local average treatment effects
* include relevant confounders in model

<!-- ### Estimation methods -->
<!-- Three methods to estimate a RDD can be distinguished: -->

<!-- Method 1: -->

<!-- select a subsample for which the value of the running variable is close to the threshold -->
<!-- problem: the smaller the sample, the larger the standard errors -->
<!-- Method 2: -->

<!-- select a larger sample and estimate parametrically -->
<!-- problem: this depends on the functional form and polynomials -->
<!-- Method 3: -->

<!-- select a subsample close to the threshold and estimate parametrically -->
<!-- extension: different functional forms on the left and right side of the cutoff -->

## Demonstration

### Demo Question: fishing mortality on crabs 
We are interested in the causal effect of fishing on crab mortality. This question is surprisingly hard to answer because it's hard to tease apart natural mortality from fishing mortality, but it is an important effect to estimate for fisheries management.

### Simulate data
```{r}
### Make column for observation ID
crab_data <- data.frame(id = seq(1, 1000),
                 
                 ### Add columns for explanatory variables
                 
                 ### Add column for treatment variable
                 fished = c(rep(0, 500), rep(1, 500)),
                 
                 ### Add column for body size
                 size = c(runif(500, min = 10, max = 80),
                          runif(500, min = 60, max = 130)),
                 
                 ### And the rest of the covariates
                 sst = runif(1000, min = 10, max = 16),
                 salinity = runif(1000, min = 1, max = 10),
                 npp = runif(1000, min = 0, max = 1),
                 
                 ### And the error term
                 error = rnorm(1000, mean = 0, sd = 2))

### Center size at legal catch size
crab_data <- crab_data %>%
  mutate(size_centered = size - 70)
  
### Make column for outcome variable (total mortality) 
crab_data <- crab_data %>%
  mutate(natural_mortality = 10 + -0.4*size_centered + 2*sst + 0.3*npp + 1.5*salinity + error,
         fishing_mortality = ifelse(size_centered < 0 & fished == 0, 
                                    10 + -0.1*size_centered,
                                    ifelse(size_centered < 0 & fished == 1,
                                           30 + 0.4*size_centered,
                                           ifelse(size_centered > 0 & fished == 0,
                                                  10 + -0.1*size_centered,
                                                  30 + 0.4*size_centered))),
         total_mortality = natural_mortality + fishing_mortality)
```

#### Visualize the data
```{r}
### Visualize fished/unfished
ggplot(crab_data) +
  geom_boxplot(aes(x = size, group = fished)) +
  geom_vline(xintercept = 70)

### Visualize mortality outcomes   
ggplot(crab_data) + 
  geom_point(aes(x = size_centered,
                 y = natural_mortality,
                 color = fished))
ggplot(crab_data) + 
  geom_point(aes(x = size_centered,
                 y = fishing_mortality,
                 color = fished))
ggplot(crab_data) +
  geom_point(aes(x = size_centered,
                 y = total_mortality,
                 color = fished))

### Visualize covariates
ggplot(crab_data) +
  geom_point(aes(x = size_centered, 
                 y = sst,
                 color = fished))
ggplot(crab_data) +
  geom_point(aes(x = size_centered, 
                 y = salinity,
                 color = fished))
ggplot(crab_data) +
  geom_point(aes(x = size_centered, 
                 y = npp,
                 color = fished))
```

### Step 1: Determine if process of assigning treatment is rule-based

```{r housing, fig.cap="Example: Rule-based example with cut off:  fishing size limits of crabs", out.width='70%', echo=F }
knitr::include_graphics("rdd_demo/crabtresh.png")
```
 
In order to be legally harvest, crabs must be larger than 70mm. Crabs smaller than 70mm are not legal to harvest. Harvesting is thus rule-based, according to size. Here, we would probably expect mortality to decline with body size, but the harvest rule changes this relationship at the discontinuity.

<!-- In order to join the tutoring program,  students have to score 70 points or lower on the entrance exam. Students who score higher than 70 are not eligible for the program. Since we have a clear 70-point rule, we can assume that the process of participating in the tutoring program is rule-based. -->

### Step 2: Determine if the design is fuzzy or sharp

Since we know that the program was applied based on a rule, we next want to figure out how strictly the rule was applied (e.g. was there a lot of illegal harvest of crabs that were too small? Were all crabs over 70mm harvested? ).The threshold was 70 mm for legal harvest — e.g., did people who caught crabs that scored 68 mm slip through cracks? The easiest way to check this is with a graph, and we can get exact numbers to verify with a table. 

<!-- The threshold was 70 points on the test—did people who scored 68 slip through bureaucratic cracks and not participate, or did people who scored 73 sneak into the program? The easiest way to check this is with a graph, and we can get exact numbers with a table. -->

```{r check-fuzzy-sharp}
ggplot(crab_data, aes(x = size_centered, y = fishing_mortality, color = fished)) +
  # Make points small and semi-transparent since there are lots of them
  geom_point(size = 0.5, alpha = 0.5,
             position = position_jitter(width = 0, height = 0.25, seed = 1234)) +
  # Add vertical line
  geom_vline(xintercept = 0) +
  # Add labels
  labs(x = "Size (centered on 70 as cut-off)", y = "Fished or not") +
  # Turn off the color legend, since it's redundant
  guides(color = "none")
```
This discontinuity looks fuzzy rather than sharp  We see some evidence of non-compliance around the size-based harvest rules. We will verify in Step 3. 

```{r echo=FALSE, out.width="75%",fig.cap="Comparison of Fuzzy vs Sharp Discontinuities from Causal Inference: The MixTape by Cummingham", out.width='70%', echo=F } 
knitr::include_graphics("rdd_demo/fuzzy_or_sharp.png", error = FALSE)
```

<!-- This looks pretty sharp—it doesn't look like people who scored under 70 participated in the program. We can verify this with a table in the next Step. . There are no people where `entrance_exam` is greater than 70 and `tutoring` is false, and no people where `entrance_exam` is less than 70 and `tutoring` is true. -->

### Step 3: Check for discontinuity in running variable around cutoff point

We next verify  our conclusions from the above visualization that the design is a fuzzy discontinuity with a table examining if  there crabs under 70 mm harvested, and some over 70mm that weren't. 
```{r fuzzy-sharp-table}
crab_data  %>%
    group_by(fished, size_centered<= 0) %>%
summarize(count = n())
```

Based on the table, we can conclude this is a fuzzy design because there are some crabs over the cut-off that were not fished, and some under that were fished. 


### Step 4: Check for discontinuity in outcome across running variable

Next, we need to see if any crabs self selected on either side of the size threshold; this seems unlikely. But, first, we'll make a histogram of the running variable (size) and see if there are any big jumps around the threshold:

```{r check-running-discontinuity}
 ggplot(crab_data, aes(x = size_centered, fill = fished)) +
  geom_histogram(binwidth = 2, color = "white", boundary = 0) +
  geom_vline(xintercept = 0) +
 labs(x = "Size", y = "Count", fill = "Legal to fish")
```

Here it doesn't look like there's a jump around the cutoff. There's a tiny visible difference between the height of the bars right before and right after the 70-mm sie threshold (centered at 0), but it seems to follow the general shape of the overall distribution.

### Step 5: Measure the size of the effect

There's a fuzzy discontinuity, but how big is it? And is it statistically significant?

### Fuzzy RDD as IV 
This is likely a fuzzy RDD set up: some crabs < 70mm are probably harvested illegally, and fishers are not catching every crab > 70mm. So the treatment assigned is not necessarily the treatment received. To estimate the effect of fishing on total crab mortality in a fuzzy RDD, we take a two stage least squares approach (using a the fuzzy RDD as an IV.

*Instruments* let us isolate causal effects for just compliers: they let us find *the complier average causal effect, or CACE* (the effect of a treatment for subjects/units who comply with the experimental treatment assigned to their sample group).
 
 In this case, the instrument is fairly easy and straightforward: we create a variable that indicates if someone is above or below the threshold. That's all. This variable essentially measures *what should have happened* rather than what actually happened.

Surprisingly, it meets all the qualifications of an instrument too:

- **Relevance** ($Z \rightarrow X$ and $\operatorname{Cor}(Z, X) \neq 0$): The cutoff causes access to fishing of crabs that leads to mortality.
- **Exclusion** ($Z \rightarrow X \rightarrow Y$ and $Z \nrightarrow Y$ and $\operatorname{Cor}(Z, Y | X) = 0$): The cutoff causes fishing mortality *only through* the harvest program.
- **Exogeneity** ($U \nrightarrow Z$ and $\operatorname{Cor}(Z, U) = 0$): Unobserved confounders between the harvest program and fishing mortality are unrelated to the cutoff, since it may be biologically meaningful but the exact number is somewhat arbitrary.

### Analyze fuzzy RDD

First we will create the IV from the cut-off.  We have already centered the running variable (size) on 0, so now we just need to create an indicator variable if the size if above or below 0. 

##NEED TO FINISH 
```{r make-instrument}
size_centered <- crab_data %>%
  mutate(above_cutoff  = size_centered >= 0,
         below_cutoff = size_centered <= 0)
```

#### 2SLS 
We could manually run the first stage model, generate predicted `tutoring` and then use those predicted values in the second stage model [like we did in the instrumental variables example](WEBSITE), but that's tedious and nobody wants to do all that work. We'll use `iv_robust()` from the **estimatr** package instead. 

Note:  be careful!  if there are missing values (in D), you may fail to replicate the fuzzy effect by hand
sum(is.na(crab_data$fished)) #ok for the simulated data 

Instead, we need to run a 2SLS model that includes our instrument in the first stage, which will then remove the endogeneity built into participation in the program. We'll estimate this set of models:

```{r}
### Create variables
X <- crab_data$size_centered # distance from size to cutoff
D <- crab_data$fished # treatment: indicator for whether the crab was fished or not
Y <- crab_data$total_mortality # outcome 

### First Stage: T on D
out <- rdrobust(D, X, bwselect = "mserd")
summary(out)

### Visualize
rdplot(D, X, x.label="size", y.label = "Fished")

### Fuzzy effect of fishing on total mortality
fuzzy_out <- rdrobust(Y, X, fuzzy = D)
h <- fuzzy_out$bws[1, 1]
b <- fuzzy_out$bws[2, 1]

### equivalent to the two-step estimation below
out_tsls <- rdrobust(Y, X, h = h, b = b)
itt <- out_tsls$Estimate[1]

out_tsls_2 <- rdrobust(D, X, h = h, b = b)
fs <- out_tsls_2$Estimate[1]

itt/fs

# Rdrobust (sharp) on Y
fit_sharp <- rdrobust(Y, X, vce = "nn", cluster = X)
summary(fit_sharp)

# Rdrobust (fuzzy) on Y
fit_fuzzy <- rdrobust(Y, X, fuzzy = D, vce = "nn", cluster = X)
summary(fit_fuzzy)

# Rdplot on Y1
rdplot(Y, X)


# Rddensity
#----------
out = rddensity(X)
summary(out)

```


##NEED TO FINISHED - IS THIS RIGHT???
$$
\begin{aligned}
\widehat{\text{Fished}} &= \gamma_0 + \gamma_1 \text{Size}_\text{centered} + \gamma_2 \text{Below cutoff} + \omega \\
\text{Fishing Mortality} &= \beta_0 + \beta_1 \text{Size}_\text{centered} + \beta_2 \widehat{\text{Fished}} + \epsilon
\end{aligned}
$$
