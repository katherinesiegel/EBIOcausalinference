{
  "hash": "2616055c1150f6250d31d783dcf234f3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression Discontinuinty Designs\"\nauthor: \"Laura Dee & Katherine Siegel\"\ndate: \"3/20/2023\"\noutput: html_document\n---\n\n\n\n\n\n<!-- https://rpubs.com/phle/r_tutorial_regression_discontinuity_design -->\n\n\n\n\n\n\n\n\n\n\n\n# The key concept\n\nA threshold in a continuous variable determines treatment assignment \n\nRunning variable (or “score”), X: a continuously distributed variable with a clearly defined cutoff (c) that determines which units are assigned to treatment and which ones are assigned to control.\n\nPrior to the treatment, the outcome should not differ between the treatment and control group (*continuity assumption*). The distribution of the variable which indicates the threshold should have no jumps around this cutoff value.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example using an arbitrary test score cut-off for being enrolled in tutoring programs on learning outcomes, from Andrew Heiss](rdd_demo/testscore_example.png){width=70%}\n:::\n:::\n\n\n\n\n\n# Theory\n\n## There are two different variants of the RDD:\n\n> * sharp RDD: the threshold separates the treatment and control group exactly\n>\n> * fuzzy RDD: the threshold influences the probability of being treated.  this is in fact an instrumental variable approach (estimating a Local Average Treatment Effect [LATE])\n\nThe value of the outcome (Y) for individuals just below the threshold is the missing counterfactual outcome. It increases continuously with the cutoff variable, as opposed to the treatment.\n\nHere are some nice elaborations and fifures on these two variants of RDD from the [World Bank](https://dimewiki.worldbank.org/Regression_Discontinuity)\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sharp vs Fuzzy RDD illustration from the World Bank](rdd_demo/worldbankRDD.png){width=70%}\n:::\n:::\n\n\n\n\n### Sharp RDD\n\"In sharp designs, the probability of treatment changes from 0 to 1 at the cutoff. There are no cross-overs and no non-complance. For example, if a scholarship award is given to all students above a threshold test score of 80%, then the assignment rule defines treatment status deterministically with probabilities of 0 or 1. Thus, the design is sharp.\n\n### Fuzzy RDD\nIn fuzzy designs, the probability of treatment is discontinuous at the cutoff, but not to the degree of a definitive 0 to 1 jump. For example, if food stamp eligibility is given to all households below a certain income, but not all households receive the food stamps, then the assignment rule defines treatment status probabilistically but not perfectly. Thus, the design is fuzzy. The fuzziness may result from imperfect compliance with the law/rule/program; imperfect implementation that treated some non-eligible units or neglected to treat some eligible units; spillover effects; or manipulation of the eligibility index.\n\nA fuzzy design assumes that, in the absence of the assignment rule, some of those who take up the treatment would not have participated in the program. The eligibility index acts as a nudge. The subgroup that participates in a program due to the selection rule is called compliers (see e.g. [Angrist and Imbens (1994)](https://pdfs.semanticscholar.org/8714/260129e51abb09fd89d6ff79065af17bb106.pdf), and [Imbens, Angrist, and Rubin (1996))](http://www.math.mcgill.ca/dstephens/AngristIV1996-JASA-Combined.pdf); under the RDD, the treatment effects are estimated only for the group of compliers.\"\n\n### Advantages of RDD\nWith an RDD approach some assumptions can be tested. Individuals or units close to the threshold are nearly identical, except for characteristics which are affected by the treatment.\n\nRDD's strengths include that we can:\n\n* illustrate the design graphically\n* test some of the underlying assumptions and support arguments through data visualization\n* reliably (unbiased) estimates local average treatment effects\n* include relevant confounders in model\n\n<!-- ### Estimation methods -->\n<!-- Three methods to estimate a RDD can be distinguished: -->\n\n<!-- Method 1: -->\n\n<!-- select a subsample for which the value of the running variable is close to the threshold -->\n<!-- problem: the smaller the sample, the larger the standard errors -->\n<!-- Method 2: -->\n\n<!-- select a larger sample and estimate parametrically -->\n<!-- problem: this depends on the functional form and polynomials -->\n<!-- Method 3: -->\n\n<!-- select a subsample close to the threshold and estimate parametrically -->\n<!-- extension: different functional forms on the left and right side of the cutoff -->\n\n\n# Application Demo \n\nLoad required packages. In this demo, we will use the package \"rdrobust\" \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"rdrobust\",\n                 repos = \"http://cran.us.r-project.org\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nThe downloaded binary packages are in\n\t/var/folders/l3/b0f69vj53_33485r27zvymn00000gp/T//RtmpT0ThjO/downloaded_packages\n```\n\n\n:::\n\n```{.r .cell-code}\ninstall.packages(\"rddensity\",\n                 repos = \"http://cran.us.r-project.org\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nThe downloaded binary packages are in\n\t/var/folders/l3/b0f69vj53_33485r27zvymn00000gp/T//RtmpT0ThjO/downloaded_packages\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)  # ggplot(), %>%, mutate(), and friends\n# library(broom)  # Convert models to data frames\nlibrary(rdrobust)  # For robust nonparametric regression discontinuity\nlibrary(rddensity)  # For nonparametric regression discontinuity density tests\n# library(modelsummary)  # Create side-by-side regression tables\n```\n:::\n\n\n\n\n\n<!-- ### Simple example of applying the rdrobust function -->\n<!-- ```{r, include=TRUE} -->\n<!-- x<-runif(1000,-1,1) # running variable  -->\n<!-- y<-5+3*x+2*(x>=0)+rnorm(1000) #outcome with a cut off c at 0  -->\n<!-- rdrobust(y,x) #apply rdrobust to view sample output  -->\n<!-- ``` -->\n\n### Simulate data for demo \n#### Demo Question: fishing mortality on crabs \nWe are interested in the causal effect of fishing on crab mortality. This question is surprisingly hard to answer because it's hard to tease apart natural mortality from fishing mortality, but it is an important effect to estimate for fisheries management.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Make column for observation ID\ncrab_data <- data.frame(id = seq(1, 1000),\n                 \n                 ### Add columns for explanatory variables\n                 \n                 ### Add column for treatment variable\n                 fished = c(rep(0, 500), rep(1, 500)),\n                 \n                 ### Add column for body size\n                 size = c(runif(500, min = 10, max = 80),\n                          runif(500, min = 60, max = 130)),\n                 \n                 ### And the rest of the covariates\n                 sst = runif(1000, min = 10, max = 16),\n                 salinity = runif(1000, min = 1, max = 10),\n                 npp = runif(1000, min = 0, max = 1),\n                 \n                 ### And the error term\n                 error = rnorm(1000, mean = 0, sd = 2))\n\n### Visualize\nggplot(crab_data) +\n  geom_boxplot(aes(x = size, group = fished)) +\n  geom_vline(xintercept = 70)\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n### center size at legal catch size\ncrab_data <- crab_data %>%\n  mutate(size_centered = size - 70)\n  \n### Make column for outcome variable (total mortality) \ncrab_data <- crab_data %>%\n  mutate(natural_mortality = 10 + -0.4*size_centered + 2*sst + 0.3*npp + 1.5*salinity + error,\n         fishing_mortality = ifelse(size_centered < 0 & fished == 0, \n                                    10 + -0.1*size_centered,\n                                    ifelse(size_centered < 0 & fished == 1,\n                                           30 + 0.4*size_centered,\n                                           ifelse(size_centered > 0 & fished == 0,\n                                                  10 + -0.1*size_centered,\n                                                  30 + 0.4*size_centered))),\n         total_mortality = natural_mortality + fishing_mortality)\n\n### Visualize mortality outcomes   \nggplot(crab_data) + \n  geom_point(aes(x = size_centered,\n                 y = natural_mortality,\n                 color = fished))\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(crab_data) + \n  geom_point(aes(x = size_centered,\n                 y = fishing_mortality,\n                 color = fished))\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(crab_data) +\n  geom_point(aes(x = size_centered,\n                 y = total_mortality,\n                 color = fished))\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n\n```{.r .cell-code}\n### Visualize covariates\nggplot(crab_data) +\n  geom_point(aes(x = size_centered, \n                 y = sst,\n                 color = fished))\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-5.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(crab_data) +\n  geom_point(aes(x = size_centered, \n                 y = salinity,\n                 color = fished))\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-6.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(crab_data) +\n  geom_point(aes(x = size_centered, \n                 y = npp,\n                 color = fished))\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-4-7.png){width=672}\n:::\n:::\n\n\n\n\n\n## Step 1: Determine if process of assigning treatment is rule-based\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example: Rule-based example with cut off:  fishing size limits of crabs](rdd_demo/crabtresh.png){width=70%}\n:::\n:::\n\n\n\n\n \nIn order to be legally harvest, crabs must be larger than 70mm. Crabs smaller than 70mm are not legal to harvest. Harvesting is thus rule-based, according to size. Here, we would probably expect mortality to decline with body size, but the harvest rule changes this relationship at the discontinuity.\n\n<!-- In order to join the tutoring program,  students have to score 70 points or lower on the entrance exam. Students who score higher than 70 are not eligible for the program. Since we have a clear 70-point rule, we can assume that the process of participating in the tutoring program is rule-based. -->\n\n## Step 2: Determine if the design is fuzzy or sharp\n\nSince we know that the program was applied based on a rule, we next want to figure out how strictly the rule was applied (e.g. was there a lot of illegal harvest of crabs that were too small? Were all crabs over 70mm harvested? ).The threshold was 70 mm for legal harvest — e.g., did people who caught crabs that scored 68 mm slip through cracks? The easiest way to check this is with a graph, and we can get exact numbers to verify with a table. \n\n<!-- The threshold was 70 points on the test—did people who scored 68 slip through bureaucratic cracks and not participate, or did people who scored 73 sneak into the program? The easiest way to check this is with a graph, and we can get exact numbers with a table. -->\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(crab_data, aes(x = size_centered, y = fishing_mortality, color = fished)) +\n  # Make points small and semi-transparent since there are lots of them\n  geom_point(size = 0.5, alpha = 0.5,\n             position = position_jitter(width = 0, height = 0.25, seed = 1234)) +\n  # Add vertical line\n  geom_vline(xintercept = 0) +\n  # Add labels\n  labs(x = \"Size (centered on 70 as cut-off)\", y = \"Fished or not\") +\n  # Turn off the color legend, since it's redundant\n  guides(color = \"none\")\n```\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/check-fuzzy-sharp-1.png){width=672}\n:::\n:::\n\n\n\n\nThis discontinuity looks fuzzy rather than sharp  We see some evidence of non-compliance around the size-based harvest rules. We will verify in Step 3. \n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of Fuzzy vs Sharp Discontinuities from Causal Inference: The MixTape by Cummingham](rdd_demo/fuzzy_or_sharp.png){width=70%}\n:::\n:::\n\n\n\n\n\n<!-- This looks pretty sharp—it doesn't look like people who scored under 70 participated in the program. We can verify this with a table in the next Step. . There are no people where `entrance_exam` is greater than 70 and `tutoring` is false, and no people where `entrance_exam` is less than 70 and `tutoring` is true. -->\n\n## Step 3: Check for discontinuity in running variable around cutpoint\n\nWe next verify  our conclusionss from the above visualization that the design is a fuzzy disconintuinity with a table examinging if  there crabs under 70 mm harvested, and some over 70mm that weren't. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrab_data  %>%\n    group_by(fished, size_centered<= 0) %>%\nsummarize(count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'fished'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n# Groups:   fished [2]\n  fished `size_centered <= 0` count\n   <dbl> <lgl>                <int>\n1      0 FALSE                   67\n2      0 TRUE                   433\n3      1 FALSE                  425\n4      1 TRUE                    75\n```\n\n\n:::\n:::\n\n\n\n\n\nBased on the table, we can conclude this is a fuzzy design becuase there are some crabs over the cut-off that were not fished, and some under that were fished. \n\n\n## Step 4: Check for discontinuity in outcome across running variable\n\nNext, we need to see if any crabs self selected on either side of the size threshold; this seems unlikely. But, first, we'll make a histogram of the running variable (size) and see if there are any big jumps around the threshold:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n ggplot(crab_data, aes(x = size_centered, fill = fished)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  geom_vline(xintercept = 0) +\n labs(x = \"Size\", y = \"Count\", fill = \"Legal to fish\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The following aesthetics were dropped during statistical transformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/check-running-discontinuity-1.png){width=672}\n:::\n:::\n\n\n\n\n\nHere it doesn't look like there's a jump around the cutoff. There's a tiny visible difference between the height of the bars right before and right after the 70-mm sie threshold (centered at 0), but it seems to follow the general shape of the overall distribution.\n\n## Step 5: Measure the size of the effect\n\nThere's a fuzzy discontinuity, but how big is it? And is it statistically significant?\n\n### Fuzzy RDD as IV \nThis is likely a fuzzy RDD set up: some crabs < 70mm are probably harvested illegally, and fishers are not catching every crab > 70mm. So the treatment assigned is not necessarily the treatment received. To estimate the effect of fishing on total crab mortality in a fuzzy RDD, we take a two stage least squares approach (using a the fuzzy RDD as an IV.\n\n Recall from Session 12 that *instruments* let us isolate causal effects for just compliers: they let us find *the complier average causal effect, or CACE* (the effect of a treatment for subjects/units who comply with the experimental treatment assigned to their sample group).\n \n In this case, the instrument is fairly easy and straightforward: we create a variable that indicates if someone is above or below the threshold. That's all. This variable essentially measures *what should have happened* rather than what actually happened.\n\nSurprisingly, it meets all the qualifications of an instrument too:\n\n- **Relevance** ($Z \\rightarrow X$ and $\\operatorname{Cor}(Z, X) \\neq 0$): The cutoff causes access to fishing of crabs that leads to mortality.\n- **Exclusion** ($Z \\rightarrow X \\rightarrow Y$ and $Z \\nrightarrow Y$ and $\\operatorname{Cor}(Z, Y | X) = 0$): The cutoff causes fishing mortality *only through* the harvest program.\n- **Exogeneity** ($U \\nrightarrow Z$ and $\\operatorname{Cor}(Z, U) = 0$): Unobserved confounders between the harvest program and fishing mortality are unrelated to the cutoff, since it may be biologically meaningful but the exact number is somewhat arbitrary.\n\n### Analyze fuzzy RDD\n\nFirst we will create the IV from the cut-off.  We have already centered the running variable (size) on 0, so now we just need to create an indicator variable if the size if above or below 0. \n\n##NEED TO FINISHED \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsize_centered <- crab_data %>%\n  mutate(above_cutoff  = size_centered >= 0,\n         below_cutoff = size_centered <= 0)\n```\n:::\n\n\n\n\n\n#### 2SLS \nWe could manually run the first stage model, generate predicted `tutoring` and then use those predicted values in the second stage model [like we did in the instrumental variables example](WEBSITE), but that's tedious and nobody wants to do all that work. We'll use `iv_robust()` from the **estimatr** package instead. \n\nNote:  be careful!  if there are missing values (in D), you may fail to replicate the fuzzy effect by hand\nsum(is.na(crab_data$fished)) #ok for the simulated data \n\nInstead, we need to run a 2SLS model that includes our instrument in the first stage, which will then remove the endogeneity built into participation in the program. We'll estimate this set of models:\n\n##NEED TO FINISHED - IS THIS RIGHT???\n$$\n\\begin{aligned}\n\\widehat{\\text{Fished}} &= \\gamma_0 + \\gamma_1 \\text{Size}_\\text{centered} + \\gamma_2 \\text{Below cutoff} + \\omega \\\\\n\\text{Fishing Mortality} &= \\beta_0 + \\beta_1 \\text{Size}_\\text{centered} + \\beta_2 \\widehat{\\text{Fished}} + \\epsilon\n\\end{aligned}\n$$\n\n### Fuzzy nonparametric estimation\n\nWe can also use nonparametric methods to measure the size of the fuzzy gap at the cutoff. We'll use `rdrobust()`. T\n\nTo do fuzzy estimation with `rdrobust()`, use the `fuzzy` argument to specify the treatment column (or `fished` in our case). **Importantly** (and confusingly! this took me waaaaay too long to figure out!), you ***do not*** need to specify an instrument (or even create one!). All you need to specify is the column that indicates treatment status—`rdrobust()` will do all the above/below-the-cutoff instrument stuff behind the scenes for you.\n\n##NEED TO FINISHED WITH IV CREATED AS ENTRANCE EXAM\n<!-- Let's make an instrument! We'll also center the running variable just like we did with sharp regression discontinuity: -->\n<!-- ```{r make-instrument} -->\n<!-- tutoring_centered <- tutoring %>% -->\n<!--   mutate(entrance_centered = entrance_exam - 70, -->\n<!--          below_cutoff = entrance_exam <= 70) -->\n<!-- tutoring_centered -->\n<!-- ``` -->\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrdrobust(y = crab_data$fishing_mortality, x = crab_data$size_centered,\n         c = 0, fuzzy = crab_data$fished) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                 1000\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  508          492\nEff. Number of Obs.             159          153\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                  11.130       11.130\nBW bias (b)                  21.953       21.953\nrho (h/b)                     0.507        0.507\nUnique Obs.                     508          492\n\nFirst-stage estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.070     0.108     0.648     0.517    [-0.142 , 0.282]     \n        Robust         -         -     1.057     0.291    [-0.109 , 0.364]     \n=============================================================================\n\nTreatment effect estimates.\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    17.667     4.022     4.392     0.000     [9.783 , 25.551]    \n        Robust         -         -     4.253     0.000    [10.525 , 28.520]    \n=============================================================================\n```\n\n\n:::\n:::\n\n\n\n\n\nThat's all! Using nonparametric methods, with a triangular kernel and a bandwidth of ±12.96, the causal effect of the tutoring program for compliers in the bandwidth is 9.683.\n\nWe can (and should!) [do all the other nonparametric robustness checks that we talked about in the regression discontinuity example](/example/rdd.qmd#nonparametric-estimation), like modifying the bandwidth (ideal, half, double) and messing with the kernel (uniform, triangular, Epanechnikov) to see how robust the finding is. But again, we won't do any of that here.\n\n\n### Useful references and websites for more resources\n\nhttps://dimewiki.worldbank.org/Regression_Discontinuity\n\nthe MixTape by Scott Cummingham: https://mixtape.scunning.com/06-regression_discontinuity\n\nRDD with interactions: https://www.jepusto.com/rdd-interactions/\n\n### Simulate Data\nModified from the MixTape by Scott Cummingham: https://mixtape.scunning.com/06-regression_discontinuity\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n# simulate the data\ndat <- tibble(\n  x = rnorm(1000, 50, 25)\n) %>%\n  mutate(\n    x = if_else(x < 0, 0, x)\n  ) %>%\n  filter(x < 100)\n\n# cutoff at x = 70, no jump\ndat <- dat %>% \n  mutate(\n    D  = if_else(x > 70, 1, 0),\n    y1 = 25 + 0 * D + 1.5 * x + rnorm(n(), 0, 20)\n  )\n\nggplot(aes(x, y1, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.5) +\n  geom_vline(xintercept = 70, colour = \"grey\", linetype = 2)+\n  stat_smooth(method = \"lm\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y1)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## simulate the discontinuity\ndat <- dat %>%\n  mutate(\n    y2 = 25 + 40 * D + 1.5 * x + rnorm(n(), 0, 20)\n  )\n\n# figure\nggplot(aes(x, y2, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.5) +\n  geom_vline(xintercept = 70, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"lm\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# simultate nonlinearity\ndat <- tibble(\n    x = rnorm(1000, 100, 50)\n  ) %>% \n  mutate(\n    x = case_when(x < 0 ~ 0, TRUE ~ x),\n    D = case_when(x > 140 ~ 1, TRUE ~ 0),\n    x2 = x*x,\n    x3 = x*x*x,\n    y3 = 10000 + 0 * D - 100 * x + x2 + rnorm(1000, 0, 1000)\n  ) %>% \n  filter(x < 280)\n\nggplot(aes(x, y3, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.2) +\n  geom_vline(xintercept = 140, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"lm\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(aes(x, y3, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.2) +\n  geom_vline(xintercept = 140, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"loess\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](RDD_LD_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n\n\n\n<!-- <!-- from https://www.jepusto.com/rdd-interactions/ --> -->\n<!-- ```{r, include=TRUE} -->\n<!-- set.seed(20160124) -->\n<!-- simulate_RDD <- function(n = 2000, R = rnorm(n, mean = qnorm(.2))) { -->\n<!--   n <- length(R) -->\n<!--   T <- as.integer(R > 0) -->\n<!--   X1 <- 10 + 0.6 * (R - qnorm(.2)) + rnorm(n, sd = sqrt(1 - 0.6^2)) -->\n<!--   X2 <- sample(LETTERS[1:4], n, replace = TRUE, prob = c(0.2, 0.3, 0.35, 0.15)) -->\n<!--   Y0 <- 0.4 * R + 0.1 * (X1 - 10) + c(A = 0, B = 0.30, C = 0.40, D = 0.55)[X2] + rnorm(n, sd = 0.9) -->\n<!--   Y1 <- 0.35 + 0.3 * R + 0.18 * (X1 - 10) + c(A = -0.50, B = 0.30, C = 0.20, D = 0.60)[X2] + rnorm(n, sd = 0.9) -->\n<!--   Y <- (1 - T) * Y0 + T * Y1 -->\n<!--   data.frame(R, T, X1, X2, Y0, Y1, Y) -->\n<!-- } -->\n\n<!-- RD_data <- simulate_RDD(n = 2000) -->\n<!-- ``` -->\n\nWe can check the size two different ways: parametrically (i.e. using `lm()` with specific parameters and coefficients), and nonparametrically (i.e. not using `lm()` or any kind of straight line and instead drawing lines that fit the data more precisely). We'll do it both ways.\n\n### Parametric estimation\n\nFirst we'll do it parametrically by using linear regression. Here we want to explain the variation in final scores based on the entrance exam score and participation in the tutoring program:\n\n$$\n\\text{Exit exam} = \\beta_0 + \\beta_1 \\text{Entrance exam score}_\\text{centered} + \\beta_2 \\text{Tutoring program} + \\epsilon\n$$\n\n### Nonparametric estimation\n\nInstead of using linear regression to measure the size of the discontinuity, we can use nonparametric methods. Essentially this means that R will not try to fit a straight line to the data—instead it'll curve around the points and try to fit everything as smoothly as possible.\n\nThe `rdrobust()` function makes it really easy to measure the gap at the cutoff with nonparametric estimation. Here's the simplest version:\n",
    "supporting": [
      "RDD_LD_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}